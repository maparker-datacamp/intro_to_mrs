


# Data Management with RRE:    
# Simple Transformations


## Intro

Welcome to Data Management with Revolution R Enterprise. People love to say 
that getting the data clean is 80% of the work in data analysis. If anything,
that's a low estimate. Chances are that you're going to be spending a lot of
time checking your variables for weird values, removing erroneous records,
and creating new variables that are optimized for analysis. In this session
and the next, we'll cover all the functions you need to get your dataset into
shape.


## Transforms for One Variable

First, let's import some data into an XDF file.

```{r import}

# First, set up pointers to the source XDF file
sourcePath <- file.path(rxGetOption("sampleDataDir"), "DJIAdaily.xdf")

# And a temporary file
xdfPath <- tempfile(fileext = ".xdf")

# Import from the source file to our temporary one
rxImport(inData = sourcePath,
         outFile = xdfPath)

# Look at the top several rows
rxDataStep(xdfPath, numRows = 10)

# Let's see what types those variables are
rxGetInfo(xdfPath, getVarInfo = TRUE)

```

This dataset includes key details about the Dow Jones Industrial Average.
As you can see, it includes the Open and Close, High and Low, and the Volume.
The dataset covers trading days starting in... well... I don't remember
what dates this dataset covers. Let's take a look.

Now - from the output of rxGetInfo, I can see that my Date variable has
unfortunately been read in as a character variable. That's a pretty common
problem. I do have a Year variable that shows me that the data covers 1928
through 2010. But if I didn't have that variable, or if
I needed to know the exact dates, I'd have to do some work.

In open-source R, we'd probably just use the as.Date function to create a 
new variable on the data.frame. In Revolution R Enterprise, the idea is the
same - but because I'm working with an XDF file, I need to use a Revolution R
function called rxDataStep. rxDataStep is the key function for working with
XDF files, so you'll see a lot of it in this session.


```{r char_to_date}

rxDataStep(inData = xdfPath,
           outFile = xdfPath,
           transforms = list(Date2 = as.Date(Date)),
           overwrite = TRUE
)

```

As you can see, rxDataStep has a lot in common with rxImport: an inData
argument that species which file should be read and an outFile that specifies
where the modified data should be written.

Next, we have the transforms argument, which is where we tell rxDataStep
what we'd like to change in the data. In this case, that's just one thing:
we'd like to convert the original Date variable from a character vector to
a Date vector, which we'll name Date2. I use the same function I would in
open-source R, as.Date; it's just inside of rxDataStep so that it can work
with the XDF file.

It's also inside a list. The transforms argument will always take a named list,
where you put the new variable name on the left-hand side and the expression
that generates the new variable on the right-hand side. This seems a little
strange at first, especially with just one transformation, but it should
feel more normal after we've looked at a few examples of transforming
multiple variables.

Finally, because I'm modifying *all* of the chunks in the XDF file, I need
to set overwrite to TRUE. RRE always wants you to think twice before you risk
overwriting data, which means we'll use overwrite a lot during this phase of
the analysis.

```{r char_to_date_check}

rxGetInfo(xdfPath, getVarInfo = TRUE)


```

Date2 shows us that the data spans from October first, 1928 through 
December second, 2010. Good to know.


## Transforms for Multiple Variables

Let's add a second transformation. Converting a character variable to a date,
as we've just done,
is a common data cleaning task, but sometimes you might have separate 
year, month, and day variables that you have to manually combine into a 
proper Date. We've got those components in our current dataset, so let's 
combine them to see how that works. I'll leave in the first transformation
so you can see how rxDataStep handles multiple transformations in one pass.


```{r ints_to_date}

rxDataStep(inData = xdfPath,
           outFile = xdfPath,
           transforms = list(
               Date2 = as.Date(Date),
               combinedDate = paste(Year, Month, DayOfMonth, sep = "-"),
               Date3 = as.Date(combinedDate)
           ),
           overwrite = TRUE
)

rxGetInfo(xdfPath, getVarInfo = TRUE)


```

I've added two new transformations to the list; you can see that each entry 
is separated from the others by a comma. 
In the second transformation, I'm combining the year, month, and day variables 
into a single character string, separated by a hyphen.
Because that date is formatted in a way that R recognizes, I
can simply pass it on to as.Date in the next transformation to create Date3.

Now, I could easily paste the variables together and convert them into a date
in one transformation, but I've split that into two actions to demonstrate
another important feature of rxDataStep: variables that you create in the
transforms list can be immediately used in subsequent transformations.

Remember: when you're dealing with really big data, one of the major
bottlenecks is just reading and writing the data. RRE and its functions are
designed to let you do that as little as possible - so it's a good idea
to combine as many of your transformations into a single rxDataStep as possible.


## Dropping Variables


```{r lotta_vars}

rxDataStep(xdfPath, numRows = 10)

```

Okay... we've got a *lot* of date variables on this dataset, now. I probably
don't want all this redundant data taking up space on my disk or being read
into memory, so let's get rid of some of these variables. rxDataStep can do
that, too:

```{r drop_vars}

xdfSubset <- tempfile(fileext = ".xdf")

rxDataStep(inData = xdfPath,
           outFile = xdfSubset,
           varsToDrop = c("Date", "Year", "Month", "DayOfMonth",
                          "DaysSince1928", "YearFrac", "combinedDate", "Date3")
)

rxDataStep(xdfSubset, numRows = 10)

```

If it were more convenient to name the variables I wanted to keep instead of
the ones I wanted to drop, I could use varsToKeep instead:

```{r keep_vars}

xdfSubset <- tempfile(fileext = ".xdf")

rxDataStep(inData = xdfPath,
           outFile = xdfSubset,
           varsToKeep = c("Date2", "Open", "High", "Low", "Close", "Volume",
                          "Adj.Close", "DayOfWeek")
)

rxDataStep(xdfSubset, numRows = 10)

```

A nice side-effect of varsToKeep is that the columns are then sorted in the
order you've specified.


## Subsetting

By the way: you've seen me use the numRows argument a few times to peek at
the top ten rows of my XDF file. numRows is a simple way to create a subset
of your data, but most of the time you'll want to create subsets based on some
criteria. In rxDataStep, I'd use the rowSelection argument for that. 
rowSelection works much like the subset() - I can use any number of comparisons
or logical vectors to pick out the rows that I want. For example, I could
get just the data from the year 2000 onward like this:

```{r subset_2000}

xdf2000 <- tempfile(fileext = ".xdf")

rxDataStep(inData = xdfSubset,
           outFile = xdf2000,
           rowSelection = Date2 > as.Date("1999-12-31")
)

```

Or maybe I just want to look at Monday opens and Friday closes:

```{r subset_MonFri}

xdfMonFri <- tempfile(fileext = ".xdf")

rxDataStep(inData = xdfSubset,
           outFile = xdfMonFri,
           rowSelection = DayOfWeek %in% c("Monday", "Friday"),
           varsToKeep = c("Date2", "DayOfWeek", "Open", "Close")
)

```

Subsetting with a combination of varsToKeep, varsToDrop, and rowSelection 
is a great way to dramatically speed up your analyses. The less data RRE has
to read in, the faster it goes.



## Scaling

So now our dataset is in good shape - all the variables are in a suitable
format, at least. The price-related variables are all on pretty similar scales,
between forty and fourteen thousand, but Volume is orders of magnitude larger -
ranging from 130,000 into the billions. Let's suppose that for our analysis,
it would be useful to have Volume scaled from zero to one.

Based on what we've seen so far, it would be reasonable to try to scale it
much the way we would in open-source R: subtract the all-time minimum Volume 
from each day's Volume, then divide by the difference between the all-time 
maximum volume and the all-time minimum. 

```{r naive_scaling}

# Reasonable but wrong
rxDataStep(inData = xdfSubset,
           outFile = xdfSubset,
           transforms = list(VolumeScaled = 
               (Volume - min(Volume)) / (max(Volume) - min(Volume))
           ),
           overwrite = TRUE
)

```

It's always a good idea to check the results of a transformation. Let's take
a look to see if all of the values are between zero and one:

```{r naive_histogram, echo = FALSE}

library(ggplot2)

# Extract the data into a data.frame
compareVolumes <- rxDataStep(xdfSubset)


# Histogram of VolumeScaled
ggplot(compareVolumes, aes(x = VolumeScaled)) +
    geom_histogram(color = "white") +
    labs(title = "Scaled values between zero and one? Yep")


```

Looks good! This scaling should also be a linear transformation - so let's
check that:

```{r naive_scatter, echo = FALSE}


# Checking for linearity of transformation
ggplot(compareVolumes, aes(x = Volume, y = VolumeScaled)) +
    geom_point(alpha = 0.4) + 
    labs(title = "Scaled volume a linear function of volume? Nope")


```

Uh oh. Somehow there are three different lines. The one leading to the top
right of the plot looks correct - it maps the highest value of Volume to one.
But there are two other lines that are mapping very low Volumes to one.
If we look at the two variables over time:

```{r naive_timeline, echo = FALSE}

# Melt down for comparative plotting
library(reshape2)

compareVolumesMelt <- melt(compareVolumes, 
                           id.var = "Date2",
                           measure.var = c("Volume", "VolumeScaled")
)

# When does the actual volume max happen? The scaled maxes?
volumeMaxes <- rbind(
    data.frame(Date2 = with(compareVolumes, Date2[Volume == max(Volume)]),
               variable = "Volume"),
    data.frame(Date2 = with(compareVolumes, Date2[VolumeScaled == 1]),
               variable = "VolumeScaled")
)


ggplot(compareVolumesMelt, aes(x = Date2, y = value, color = variable)) +
    geom_point() +
    geom_vline(data = volumeMaxes, 
               aes(xintercept = as.numeric(Date2))) +
    facet_wrap( ~ variable, 
               nrow = 2,
               scales = "free_y") +
    labs(title = "Comparing Unscaled and Scaled Maximums")
    guides(color = FALSE)

```

... and flag the maximums of each with a vertical line, we can see that
the scaled volume fluctuates much more than the original volume and actually 
has *four* days of maximum volume, only one of which corresponds to the real
day of maximum volume.

The problem here is that rxDataStep is working through the data one chunk at
a time - which means that when we use the R functions min and max in our
transformation, they're getting the min and max values of whichever chunk is
in memory at that moment - *not* the global min and max. If we check the
metadata for our XDF,

```{r chunk_count}
rxGetInfo(xdfSubset)
```

... we can see that there are four chunks, one for each of the four
days of maximum volume.

This is a danger every time you want to do something in RRE that depends on
values that might be on other chunks - min and max, mean and median, lagging
a variable, and so on. Fortunately, it's usually pretty easy to calculate
these statistics separately and then pass them to rxDataStep. First,
calculate the summary statistic using an appropriate function. 

In this case, I'll use rxGetInfo. The minimum and maximum of all the variables
in an XDF file are pre-computed and stored as metadata in the XDF,
which means that we can get these stats almost instantaneously, because we
aren't reading the data at all.


```{r calc_minmax}

str(rxGetInfo(xdfSubset, getVarInfo = TRUE))

volumeMin <- rxGetInfo(xdfSubset, getVarInfo = TRUE)$varInfo$Volume$low
volumeMax <- rxGetInfo(xdfSubset, getVarInfo = TRUE)$varInfo$Volume$high

rxDataStep(inData = xdfSubset,
           outFile = xdfSubset,
           transformObjects = list(volumeMin = volumeMin, 
                                   volumeMax = volumeMax),
           transforms = list(VolumeScaled = 
               (Volume - volumeMin) / (volumeMax - volumeMin)),
           overwrite = TRUE
)

```


We can see the structure of the rxGetInfo using the str function. Now that we
know the structure, it's simple to pick out the min and max of Volume and
extract them into their own objects, volumeMin and volumeMax, 
just to make them easier to work with.
This is a bit unusual because we're using data in the R workspace
to supplement the data in the XDF file. In order to mix these two kinds of 
data, I need to use the transformObjects argument to pass the volumeMin and 
volumeMax objects into rxDataStep. Just like the transforms argument itself,
this is a named list.
It's usually easiest to just give the object the same name in the list that
it has in your workspace - which is why you see this strange "volumeMin
equals volumeMin" in the code here.

Finally, I just replace the min and max functions I used in transforms earlier 
with these new, pre-computed values. Let's see if it made a difference.


```{r correct_scatter, echo = FALSE}
compareVolumes2 <- rxDataStep(xdfSubset)

ggplot(compareVolumes2, aes(x = Volume, y = VolumeScaled)) +
    geom_point(alpha = 0.4) + 
    labs(title = "Scaled volume a linear function of volume? Yes!")
```

It did! That's how a linear transformation ought to look. So let's recap:
rxDataStep only has access to one chunk of data at a time, so any calculation
that requires data from another chunk *must* be computed outside of
rxDataStep, and passed in using the transformObjects argument.



## transformPackages

You might wonder why we had to explicitly pass the minimum and maximum
volume statistics into rxDataStep using the transformObjects argument. Part of
the reason is that Revolution R Enterprise is built with distributed computing
in mind, and so some chunks of data could be processed on other computers
that don't have access to your R workspace. Remember, the XDF file is on disk,
not in your R workspace. But if you pass the min and max
objects to transformObjects, rxDataStep can distribute them to all of your
nodes.

This happens in a couple of other situations, too. Imagine we wanted to
extract the year from the dates in our dataset - just pretend it wasn't on
the dataset already. There's a package called lubridate that's great for
working with dates and datetimes, and it includes a function for quickly 
extracting years from dates.

```{r extract_date}

rxDataStep(inData = xdfSubset,
           outFile = xdfSubset,
           transformPackages = "lubridate",
           transforms = list(year = year(Date2)),
           overwrite = TRUE
)

```

In order to use lubridate's year function, I need to use a new argument
called transformPackages which lets all of the nodes I'm working with know
that they'll need to load the lubridate package in order to complete this
transformation.

Another scenario where you need a supplemental argument is if you've written 
a custom function that you'd like to use inside of rxDataStep. The argument
you need in that case is transformFunc. Transformations using your own
functions can be really powerful, so we'll cover those in the next session on
advanced transformations.


## Factors

There's one more scenario in which you need to be wary of working with just
one chunk at a time, and that's when you're working with factors.
Factors are the R data type for categorical data, and every factor has a
fixed number of values that it can take, called its "levels". R won't let
you combine factors that don't have the same levels, even if the levels of
one factor contain all the levels of the other. So if you convert a variable
into a factor using one chunk of data, and it happens to have a different
set of levels than a factor made on another chunk, R won't let you combine
those two chunks.

In this session, we'll cover the simplest way to get around this limitation,
and we'll go into more depth in the next session. If your factor has just a few
levels, you can still make the transforms argument work by simply specifying
the levels you want the factor to have:


```{r factors}

rxDataStep(inData = xdfSubset,
           outFile = xdfSubset,
           transforms = list(
               DayOfWeekFactor = factor(DayOfWeek,
                                        levels = c("Monday", "Tuesday",
                                                   "Wednesday", "Thursday",
                                                   "Friday"))),
           overwrite = TRUE
)

```

Because I specified the levels inside of the factor function, every chunk
will create factors with the same levels - even if that chunk contained only
records for Monday. This is a totally manageable solution for days of the week,
months, Likert scale values, and so on - any factor with relatively few levels
that don't change often. If you had many levels, like all the cities in North
America, or levels that changed often, like current customers,
manually setting levels like this would be a liability. We'll cover factors
in greater depth in our next session on advanced transformations.



## Conclusion

That's it for this session. You should now be able to make good use of
rxDataStep to clean up and transform your data. The most critical thing to
remember is that rxDataStep can only see one chunk of your data at a time - so
any calculations that depend on two or more chunks' worth of data have to be
done outside of rxDataStep. But don't worry - we'll dig even deeper into this
issue in the Advanced Transformations session, where you'll learn powerful
methods for cross-chunk calculations. 

Take care and see you next time.




```{r cleanup, echo = FALSE, results = 'hide'}

# Delete the temporary XDFs
file.remove(xdfPath)
file.remove(xdfSubset)
file.remove(xdf2000)
file.remove(xdfMonFri)




```
